# Performance Metrics Guide

## Overview
The extension now includes comprehensive performance instrumentation to track tokenization, symbol generation, folding, and processing speed across all components.

## ðŸš€ Performance Breakthrough (v0.5.8)

**We achieved a 97% performance improvement** through systematic optimization:

| Component | Before | After | Improvement |
|-----------|--------|-------|-------------|
| Tokenization | 5,800ms | 598ms | **90% faster (10x)** |
| Symbol Generation | 6,000ms | 110ms | **98% faster (55x)** |
| Folding Ranges | 10ms | 4ms | **60% faster** |
| Structure View | 20+ sec | <1 sec | **95%+ faster** |
| **Total Startup** | **35+ sec** | **<1 sec** | **97% faster** |

### What Was Optimized

**Tokenization (10x faster):**
- Pre-compiled regex patterns (eliminate runtime compilation)
- Character-class pre-filtering (skip impossible patterns)
- Pattern ordering optimization (common patterns first)
- Line-based incremental caching (95%+ speedup on edits)

**Symbol Generation (55x faster):**
- Fixed O(nÂ²) algorithm
- Built tokensByLine index for O(1) lookups
- Eliminated repeated token array scans

**Structure View (instant):**
- Top-level only expansion (vs recursive full-tree)
- Parallel expansion with Promise.all()
- Reduced artificial delays

**Folding (2x faster):**
- Single-pass filtering (collect foldable + regions in one loop)
- Pre-filtered region processing

**Credits:**
Completed in collaboration with GitHub Copilot on November 17, 2025.

---

## Viewing Performance Metrics

### In VS Code Debug Console

1. **Open Output Panel**: `View` â†’ `Output` (or `Ctrl+Shift+U`)
2. **Select Channel**: Choose "Clarion Extensions" from the dropdown
3. **Filter for Performance**: Use the search box to filter logs

### Easy Search Patterns

Search for these patterns in the Output panel:

#### All Performance Metrics
```
ðŸ“Š PERF:
```
This shows ALL performance-related logs with metrics in an easy-to-read format.

#### Specific Operations

**Tokenization metrics:**
```
PERF: Tokenization complete
```

**Full tokenization (file open, major changes):**
```
PERF: Full tokenization
```

**Incremental tokenization (small edits):**
```
PERF: Incremental tokenization
```

**Index building:**
```
PERF: Built indexes
```

#### By Component

**Tokenizer logs:**
```
[Tokenizer] ðŸ“Š PERF:
```

**Symbol Provider logs (NEW in v0.5.8):**
```
[Server] ðŸ“Š PERF: Symbols:
[ClarionDocumentSymbolProvider] ðŸ“Š PERF:
```

**Folding Provider logs (NEW in v0.5.8):**
```
[Server] ðŸ“Š PERF: Folding:
```

**Structure View logs (NEW in v0.5.8):**
```
[StructureViewPerf] ðŸ“Š PERF:
```

**Token Cache logs:**
```
[TokenCache] ðŸ“Š PERF:
```

**Document Structure logs:**
```
[DocumentStructure] ðŸ“Š PERF:
```

## Understanding the Metrics

### Symbol Generation (NEW in v0.5.8)
```
[Server] ðŸ“Š PERF: Symbols: complete | total_ms=110.50, token_ms=0.01, symbol_ms=110.35, symbols=19
[ClarionDocumentSymbolProvider] ðŸ“Š PERF: Symbol: build index | time_ms=2.50, lines=13473
```

**Metrics:**
- `total_ms`: Total time for symbol generation
- `token_ms`: Time getting tokens (usually cached = 0.01ms)
- `symbol_ms`: Time generating document symbols
- `symbols`: Number of symbols generated
- Index build shows one-time cost of building line lookup table

### Folding Generation (NEW in v0.5.8)
```
[Server] ðŸ“Š PERF: Folding: complete | total_ms=6.50, token_ms=0.01, fold_ms=6.35, ranges=4120
[Server] ðŸ“Š PERF: Folding: filter | time_ms=1.20, foldable=150, regions=25
```

**Metrics:**
- `total_ms`: Total time for folding range generation
- `token_ms`: Time getting tokens (usually cached)
- `fold_ms`: Time computing folding ranges
- `ranges`: Number of foldable regions generated
- Filter metrics show single-pass optimization results

### Structure View (NEW in v0.5.8)
```
[StructureViewPerf] ðŸ“Š PERF: executeDocumentSymbolProvider: 550.00ms, returned 19 symbols
[StructureViewPerf] ðŸ“Š PERF: Structure view refresh triggered
[StructureViewPerf] ðŸ“Š PERF: Active editor changed to: MyFile.clw
```

**Metrics:**
- Shows client-side timing for VS Code symbol provider calls
- Includes editor change events and refresh operations
- Total time from user action to tree populated

### Tokenization Complete
```
[Tokenizer] ðŸ“Š PERF: Tokenization complete | total_ms=45.23, lines=1234, lines_per_ms=27.3, chars=45678, chars_per_ms=1009, tokens=5432, tokens_per_ms=120.1, split_ms=2.34, split_pct=5.2%, tokenize_ms=38.45, tokenize_pct=85.0%, structure_ms=4.44, structure_pct=9.8%
```

**Metrics:**
- `total_ms`: Total time for complete tokenization
- `lines`: Number of lines processed
- `lines_per_ms`: Processing speed (higher is better)
- `chars`: Total characters processed
- `chars_per_ms`: Character processing speed (higher is better)
- `tokens`: Number of tokens generated
- `tokens_per_ms`: Token generation speed (higher is better)
- `split_ms`: Time spent splitting into lines
- `split_pct`: Percentage of time splitting
- `tokenize_ms`: Time spent tokenizing lines
- `tokenize_pct`: Percentage of time tokenizing
- `structure_ms`: Time spent processing document structure
- `structure_pct`: Percentage of time on structure

### Incremental Tokenization
```
[TokenCache] ðŸ“Š PERF: Incremental tokenization | total_ms=8.52, changed_lines=3, retokenized_lines=5, tokens=5432, reused_pct=99.1%, detect_ms=0.45, expand_ms=0.23, build_ms=0.78, tokenize_ms=5.12, adjust_ms=0.34, merge_ms=1.23, cache_ms=0.37
```

**Metrics:**
- `total_ms`: Total incremental update time
- `changed_lines`: Lines that actually changed
- `retokenized_lines`: Lines re-tokenized (including dependencies)
- `tokens`: Final token count
- `reused_pct`: Percentage of tokens reused from cache (higher is better)
- `detect_ms`: Time detecting changes
- `expand_ms`: Time expanding to dependencies
- `build_ms`: Time building text for tokenization
- `tokenize_ms`: Time tokenizing changed lines
- `adjust_ms`: Time adjusting line numbers
- `merge_ms`: Time merging with cached tokens
- `cache_ms`: Time updating cache

### Full Tokenization
```
[TokenCache] ðŸ“Š PERF: Full tokenization | total_ms=52.34, tokenize_ms=48.23, cache_build_ms=2.89, tokens=5432
```

**Metrics:**
- `total_ms`: Total time including cache building
- `tokenize_ms`: Time spent in tokenizer
- `cache_build_ms`: Time building line-based cache
- `tokens`: Number of tokens generated

### Index Building
```
[DocumentStructure] ðŸ“Š PERF: Built indexes | time_ms=1.45, tokens=5432, labels=234, lines=1234, struct_types=12
```

**Metrics:**
- `time_ms`: Time to build all indexes
- `tokens`: Number of tokens indexed
- `labels`: Number of labels indexed
- `lines`: Number of lines indexed
- `struct_types`: Number of unique structure types

## Performance Targets

### Excellent Performance (v0.5.8 Achieves These!)
- **Full tokenization**: < 100ms per 1000 lines (~600ms for 14k lines) âœ…
- **Symbol generation**: < 150ms regardless of file size âœ…
- **Folding**: < 10ms for large files âœ…
- **Incremental update**: < 10ms for typical edits (1-10 lines) âœ…
- **Token reuse**: > 95% for small edits âœ…
- **Throughput**: > 900 chars/ms âœ…

### Previous Good Performance Targets (Pre-v0.5.8)
- **Full tokenization**: < 50ms for 1000 lines
- **Incremental update**: < 10ms for typical edits
- **Token reuse**: > 95% for small edits
- **Throughput**: > 1000 chars/ms

### Real-World Results (v0.5.8)
For a large file (14,348 lines, 532,645 chars):
- **Tokenization**: 598ms (891 chars/ms, 94.5 tokens/ms)
- **Symbol generation**: 110ms for 19 top-level symbols
- **Folding**: 6.5ms for 4,120 foldable ranges
- **Total startup**: <1 second vs 35+ seconds previously

## Analyzing Performance Issues

### Slow Full Tokenization
If `total_ms` is high for full tokenization:
1. Check `tokenize_pct` - should be 80-90%
2. If `structure_pct` is high (>15%), document structure processing is slow
3. If `split_pct` is high (>10%), line splitting is slow

### Slow Incremental Updates
If incremental updates are slow:
1. Check `reused_pct` - should be >95% for small edits
2. If `retokenized_lines` is much larger than `changed_lines`, dependency expansion is too aggressive
3. Check `tokenize_ms` - should be proportional to `retokenized_lines`

### Unexpected Full Tokenization
If you see "Full tokenization" when you expected incremental:
- Check if >30% of lines changed (auto-fallback)
- Check if >20% of document length changed (auto-fallback)

## Disabling Performance Logging

To reduce log noise, set logger level to "warn" or "error":

In `server/src/ClarionTokenizer.ts`, `TokenCache.ts`, or `DocumentStructure.ts`:
```typescript
logger.setLevel("warn"); // or "error"
```

This will disable INFO-level logs including performance metrics while keeping warnings and errors.
